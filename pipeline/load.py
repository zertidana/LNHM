"""Load script for inserting minute-by-minute data generated by transform into database."""

from os import environ as ENV, path
from dotenv import load_dotenv
import sqlalchemy
import pandas as pd

from utilities import get_logger, set_logger, load_csv_data


def insert_transformed_data(transformed_data: pd.DataFrame = None) -> None:
    """Function that calls connect function, and inserts into the Microsoft SQL database"""
    logger = get_logger()

    if transformed_data is None:
        if path.exists('data/normalised_minute_output.csv'):
            logger.info("Loading local recent data...")
            transformed_data = load_csv_data(
                'data/normalised_minute_output.csv')
            logger.info("Successfully loaded recent data!")
        else:
            logger.error(
                "No csv file found at path: data/normalised_minute_output.csv, "
                "please run the previous pipeline steps to generate it.")

    logger.info("Inserting data into database setup...")
    engine = sqlalchemy.create_engine(
        (f"mssql+pyodbc://{ENV['DB_USER']}:{ENV['DB_PASSWORD']}"
         f"@{ENV['DB_HOST']}/{ENV['DB_NAME']}?driver={ENV['DB_DRIVER']}"),
        connect_args={'connect_timeout': 10, 'TrustServerCertificate': 'yes'},
        echo=False)

    transformed_data.to_sql('FACT_plant_reading',
                            engine, index=False, if_exists='append')

    logger.info("Successfully inserted data!")


if __name__ == "__main__":
    load_dotenv()
    set_logger()
    insert_transformed_data()
